{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tidy Data with `melt`\n",
    "\n",
    "### Objectives\n",
    "\n",
    "+ Explain what tidy data is\n",
    "+ Spot messy data\n",
    "+ Transform a simple messy dataset into a tidy data set\n",
    "+ Use **`melt`** to reshape the data\n",
    "+ Use parameter **`id_vars`** to keep a column vertical\n",
    "+ Use parameter **`value_vars`** to melt columns into a single column\n",
    "\n",
    "### Resources\n",
    "+ Read Hadley Wickham's paper on [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf)\n",
    "+ Watch Hadley Wickham's talk on [tidy data](https://vimeo.com/33727555)\n",
    "+ Watch Jeff Leek's video on [tidy data](https://www.youtube.com/watch?v=whDilsFoLVY)\n",
    "+ Read the [reshaping pandas documentation page](http://pandas.pydata.org/pandas-docs/stable/reshaping.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets until now\n",
    "We have analyzed several datasets, but have not done much work to change their structure or do any preprocessing before computation. We immediately began generating results and answering questions. Producing results is typically not the first step of a data analysis. The vast majority of datasets 'in the wild' will need some amount of inspection and preprocessing. And in some cases, the entire project will just be about cleaning the data so that it can be further processed by someone else. \n",
    "\n",
    "This notebook will use many ideas formulated by Hadley Wickham to **tidy** data before introducing a few more steps in order to prepare it for machine learning and visualization.\n",
    "\n",
    "There's an infamous data science saying that goes something like this: \"data scientists spend 80% of their time cleaning data and the other 20% complaining about cleaning the data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data\n",
    "Tidy data is a term coined by Hadley Wickham, the creator of many popular R packages, to describe a specific **structure** of data that makes for easy analysis. It is recommended that you read [his paper][1] to get a more complete understanding. The basics will be covered below.\n",
    "\n",
    "Tidy data is a specific structure of data that makes analysis easier. A dataset is tidy when:\n",
    "1. Each variable forms a column\n",
    "2. Each observation forms a row\n",
    "3. Each type of observational unit forms a table\n",
    "\n",
    "Any dataset that does not meet this definition is considered \"messy\". \n",
    "\n",
    "### First example of messy data\n",
    "Messy data can appear deceptively clean and tidy, especially if you have not been exposed to it before. Let's read in some data on the average arrival delay for different airlines flying out of different cities.\n",
    "\n",
    "[1]: http://vita.had.co.nz/papers/tidy-data.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>ATL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>DFW</th>\n",
       "      <th>IAH</th>\n",
       "      <th>LAS</th>\n",
       "      <th>LAX</th>\n",
       "      <th>MSP</th>\n",
       "      <th>ORD</th>\n",
       "      <th>PHX</th>\n",
       "      <th>SFO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EV</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MQ</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NK</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OO</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline   ATL   DEN   DFW   IAH   LAS   LAX   MSP   ORD   PHX   SFO\n",
       "0       AA   4.0   9.0   5.0  11.0   8.0   3.0   1.0   8.0   5.0   3.0\n",
       "1       AS   6.0  -3.0  -5.0   1.0   2.0  -3.0   6.0   2.0  -9.0   4.0\n",
       "2       B6   NaN  12.0   4.0   NaN  11.0   2.0   NaN  23.0  20.0   5.0\n",
       "3       DL   0.0  -3.0  10.0   3.0  -3.0   3.0  -1.0   7.0  -4.0   0.0\n",
       "4       EV   7.0  14.0  10.0   3.0   NaN   NaN  10.0   8.0 -14.0   NaN\n",
       "5       F9  20.0  10.0  26.0   1.0  10.0   8.0  35.0  22.0  16.0  15.0\n",
       "6       HA   NaN   NaN   NaN   NaN  13.0   1.0   NaN   NaN   2.0   8.0\n",
       "7       MQ  21.0   NaN   8.0   7.0   NaN  28.0  72.0   6.0   NaN   NaN\n",
       "8       NK  26.0   8.0  15.0  28.0  13.0  24.0  19.0  23.0   4.0   NaN\n",
       "9       OO   9.0   7.0  23.0  12.0  -3.0   8.0   2.0  10.0   3.0   9.0\n",
       "10      UA   5.0   6.0   8.0   9.0   6.0   4.0   6.0  13.0   0.0   5.0\n",
       "11      US   1.0  -0.0   2.0  -3.0  -5.0   4.0  -3.0   2.0   3.0   3.0\n",
       "12      VX   NaN   NaN   NaN   NaN   2.0   5.0   NaN  19.0   NaN   5.0\n",
       "13      WN   5.0   5.0   NaN   NaN   7.0  11.0  -0.0   NaN   6.0   4.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_delay = pd.read_csv('../data/tidy/average_arrival_delay.csv')\n",
    "arrival_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong?\n",
    "Even though the dataset returns perfectly readable and acceptable information, it is not technically a tidy data set. Generally speaking, it is easier to perform further analysis on a tidy dataset than other datasets. The notebook titled \"Why Tidy Data?\" covers several examples that compare messy to tidy data.\n",
    "\n",
    "The main issue with the above dataset is that some of the column names are variable values themselves. At this point, you might be confused as to what exactly is meant by a 'variable'. A simple definition of a variable is **anything that is liable to change**.\n",
    "\n",
    "### What are the variable names?\n",
    "Only the **`airline`** column appears to be a variable name that is found directly in the DataFrame above. You must infer the others from the description of the problem. The variables are:\n",
    "+ airline\n",
    "+ origin airport\n",
    "+ average arrival delay\n",
    "\n",
    "### Actual Tidying\n",
    "To tidy, we need to make sure the three tidy rules are followed. Let's attempt to restructure our data so that we have a three-column DataFrame with the column names from above.\n",
    "\n",
    "* The airlines are already in a single column\n",
    "* The origin airports are column names and need to be transposed into a single column\n",
    "* The average arrival delay is tiled across the rows\n",
    "\n",
    "## Melting\n",
    "Pandas contains a DataFrame method named **`melt`**, that can take columns and stack them one-by-one on top of each other. It has two important parameter: \n",
    "\n",
    "+ **`id_vars`** - a list (or single string) of column names that you want to keep as columns.\n",
    "+ **`value_vars`** - a list (or single string) of column names that you would like to reshape into one column\n",
    "\n",
    "This 'reshaping' into one column is usually referred to as **melting**, **stacking**, or **unpivoting**. The **`id_vars`** columns will remain in the same column they currently reside, but **repeat** to align with all the newly melted values in the **`value_vars`** columns. \n",
    "\n",
    "Let's keep the **`airline`** column vertical and melt the origin airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EV</td>\n",
       "      <td>ATL</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F9</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MQ</td>\n",
       "      <td>ATL</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B6</td>\n",
       "      <td>DEN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DL</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EV</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>F9</td>\n",
       "      <td>DEN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline variable  value\n",
       "0       AA      ATL    4.0\n",
       "1       AS      ATL    6.0\n",
       "2       B6      ATL    NaN\n",
       "3       DL      ATL    0.0\n",
       "4       EV      ATL    7.0\n",
       "5       F9      ATL   20.0\n",
       "6       HA      ATL    NaN\n",
       "7       MQ      ATL   21.0\n",
       "8       NK      ATL   26.0\n",
       "9       OO      ATL    9.0\n",
       "10      UA      ATL    5.0\n",
       "11      US      ATL    1.0\n",
       "12      VX      ATL    NaN\n",
       "13      WN      ATL    5.0\n",
       "14      AA      DEN    9.0\n",
       "15      AS      DEN   -3.0\n",
       "16      B6      DEN   12.0\n",
       "17      DL      DEN   -3.0\n",
       "18      EV      DEN   14.0\n",
       "19      F9      DEN   10.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports = ['ATL', 'DEN', 'DFW', 'IAH', 'LAS', 'LAX', 'MSP', 'ORD', 'PHX', 'SFO']\n",
    "ad_melted = arrival_delay.melt(id_vars='airline', value_vars=airports)\n",
    "ad_melted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the columns with `var_name` and `value_name`\n",
    "By default, the **`melt`** method will name the column containing the old column names as **`variable`**. The column containing the values of these columns is named **`value`**.\n",
    "\n",
    "The **`melt`** method provides two additional parameters **`var_name`** and **`value_name`**. Set these parameters equal to column names of your choice.\n",
    "\n",
    "### `value_vars` is optional\n",
    "By default **`melt`** will melt all the columns that are not **`id_vars`**. You don't have to explicitly put them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>avg_arrival_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EV</td>\n",
       "      <td>ATL</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F9</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MQ</td>\n",
       "      <td>ATL</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B6</td>\n",
       "      <td>DEN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DL</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EV</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>F9</td>\n",
       "      <td>DEN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline origin_airport  avg_arrival_delay\n",
       "0       AA            ATL                4.0\n",
       "1       AS            ATL                6.0\n",
       "2       B6            ATL                NaN\n",
       "3       DL            ATL                0.0\n",
       "4       EV            ATL                7.0\n",
       "5       F9            ATL               20.0\n",
       "6       HA            ATL                NaN\n",
       "7       MQ            ATL               21.0\n",
       "8       NK            ATL               26.0\n",
       "9       OO            ATL                9.0\n",
       "10      UA            ATL                5.0\n",
       "11      US            ATL                1.0\n",
       "12      VX            ATL                NaN\n",
       "13      WN            ATL                5.0\n",
       "14      AA            DEN                9.0\n",
       "15      AS            DEN               -3.0\n",
       "16      B6            DEN               12.0\n",
       "17      DL            DEN               -3.0\n",
       "18      EV            DEN               14.0\n",
       "19      F9            DEN               10.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_melted = arrival_delay.melt(id_vars='airline', var_name='origin_airport', value_name='avg_arrival_delay')\n",
    "ad_melted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first tidy dataset\n",
    "By ensuring that each variable forms its own column, each observation is also in its own row. We now have tidy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key terms - reshaping and restructuring\n",
    "When you think of tidy data, your brain should think about the terms **reshaping** or **restructuring**. The data is being maneuvered like a jigsaw puzzle. The actual data values are not changing (though some aspects of tidy data will change the values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">In this problem, we will only look at the title column and the actor name columns. Restructure the dataset so that there are only three variables - the title of the movie, the actor number (1, 2, or 3), and the actor name. Sort the result by title, assign the DataFrame to a variable and output the first 20 rows.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell and use this dataset\n",
    "movie = pd.read_csv('../data/movie.csv')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">Using the original movie dataset (and keeping its structure), attempt to count the total appearances of each actor in the dataset regardless whether they are 1, 2, or 3. Then repeat this task with your tidy dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the **`tidy/employee_messy1.csv`** file. It contains the count of all employees by race and gender.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the **`tidy/employee_messy2.csv`** file. It contains the count of all employees by department, race and gender.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the **`tidy/employee_salary_stats.csv`** file. Save the tidy dataset to a variable and then select all the median salaries. The select all the median salaries with the original 'messy' dataset. Which one is easier to read summary statistics from?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
