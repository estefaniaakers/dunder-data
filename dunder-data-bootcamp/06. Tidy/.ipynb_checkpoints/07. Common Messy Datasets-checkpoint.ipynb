{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Common Messy Datasets\n",
    "\n",
    "### Objectives\n",
    "\n",
    "+ Identify the type of messy data\n",
    "+ Transform any messy dataset into a tidy data set\n",
    "+ Use the **`str`** accessor methods to parse strings\n",
    "\n",
    "### Prepare for this lesson by...\n",
    "+ Read the entire page [working with text data](http://pandas.pydata.org/pandas-docs/stable/text.html)\n",
    "\n",
    "### Introduction\n",
    "The previous notebooks focused on one particular type of messy dataset. A dataset where the column names are actually values and not variables. This was illustrated with the simple dataset of counts of fruits. The **`melt`** method will quickly tidy these basic datasets, but often is the case that datasets take more manipulation to make them tidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Messy Data Problems\n",
    "\n",
    "1. Column names are values, not variable names.\n",
    "1. Multiple variables are stored in one column.\n",
    "1. Variables are stored in both rows and columns.\n",
    "1. Multiple types of observational units are stored in the same table.\n",
    "1. A single observational unit is stored in multiple tables\n",
    "\n",
    "The first type of messy data was covered in the previous notebook. This notebook will cover the next three examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple variables are stored in one column\n",
    "A tidy data set needs values of a single variable stored in one column.\n",
    "\n",
    "### Column names are values in the column\n",
    "Column names appear directly as values in a single column and the value of these variables are in another column. Notice below how the **`Value`** column has both numeric and string data types and the **`Info`** column isn't a variable at all but column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'State': ['Texas', 'Arizona', 'Florida'] * 3,\n",
    "                        'Info': ['Age'] * 3 + ['Salary'] * 3 + ['Hair Color'] * 3, \n",
    "                        'Value': [10, 15, 20, 3, 4, 5, 'Brown', 'Pink','Red']},\n",
    "                 columns=['State', 'Info', 'Value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fix\n",
    "This dataset is 'overly melted', so pivoting it with the **`pivot`** method will make it tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index='State', columns='Info', values='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df.pivot(index='State', columns='Info', values='Value').reset_index()\n",
    "df_tidy.columns.name = None\n",
    "df_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data types\n",
    "Whenever we have a mix of variables in a single column, you might also have a mix of data types. It's important to check the data types after reshaping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing data types\n",
    "Both **`Age`** and **`Salary`** should be integers but instead are objects. We need to change their data types. We have seen this previously with the function **`pd.to_numeric`**, but you will also see the **`astype`** method used. They both do nearly the same thing, except **`pd.numeric`** gives you more options (which were needed in a previous notebook). We will use each here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy['Age'] = df_tidy['Age'].astype('int')\n",
    "df_tidy['Salary'] = pd.to_numeric(df_tidy['Salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two or more values are stored in the same cell\n",
    "Two or more values of the same variable or different variable can be stored in the same cell in a DataFrame. You will need to extract the desired quantities. You will need to parse the strings to extract the relevant variables. Let's take a look at a dataset with multiple variables stored in a single cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.DataFrame({'City':['Houston', 'Dallas', 'Austin'], \n",
    "                   'Geolocation':['(29.7604° N, 95.3698° W)', \n",
    "                                  '32.7767° N, 96.7970° W', \n",
    "                                  '30.2672° N, 97.7431° W']})\n",
    "geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the Variables\n",
    "The first step in tidying data is identifying the variables. The **`Geolocation`** column has quite a lot of information packed into it. We will parse it into 4 separate variables.\n",
    "+ latitude \n",
    "+ latitude direction\n",
    "+ longitude\n",
    "+ longitude direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information with regular expressions using the `str` accessor\n",
    "The **`extract`** string method takes a regular expression with **capture groups** and returns each captured group as a new column.\n",
    "\n",
    "Our regular expression has 4 capture groups. One for each variable. \n",
    "\n",
    "```\n",
    "([0-9.]+)[^A-Z]+([A-Z])\\D+([0-9.]+)[^A-Z]+([A-Z])\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "[Regex101][1] is a fantastic site to practice your regular expressions. It gives you detailed explanations of what your regular expression is doing in plain English. You can even save regular expressions as direct links. The above is regex is [saved here][2]\n",
    "\n",
    "### My Explanation\n",
    "* `([0-9.]+)` - This is a capture group that searches for one or more of the digits 0-9 and the literal `.`\n",
    "* `[^A-Z]+` - This searches for one or more non-uppercase letters\n",
    "* `([A-Z])` - This is a capture group for exactly one uppercase letter\n",
    "* `\\D+` - Finds one or more non-digits\n",
    "* The regex finishes with the first three bullet points repeating\n",
    "\n",
    "[1]: https://regex101.com/\n",
    "[2]: https://regex101.com/r/XHFHcH/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_extract = geo['Geolocation'].str.extract(r'([0-9.]+)[^A-Z]+([A-Z])\\D+([0-9.]+)[^A-Z]+([A-Z])')\n",
    "geo_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names\n",
    "Pandas defaults the column names of the resulting DataFrame to integers. We would like these new columns appended to our original DataFrame.\n",
    "\n",
    "### Creating multiple new column names\n",
    "It is possible to create several new columns in our original DataFrame by simply assigning the above resulting DataFrame to a selection of new column names as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[['latitude', 'latitude direction', 'longitude', 'longitude direction']] = geo_extract\n",
    "geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the original column\n",
    "We can remove the **`Geolocation`** column as it is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geo.drop(columns='Geolocation')\n",
    "geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and change Data Types\n",
    "Both latitude and longitude are clearly supposed to be numeric (floats) but since they were extracted from a string, remain as strings. Let's change them to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo['latitude'] = geo['latitude'].astype('float')\n",
    "geo['longitude'] = geo['longitude'].astype('float')\n",
    "geo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables are stored in both rows and columns\n",
    "A more difficult situation occurs when variables are stored down a column and across the column names. Pivoting and melting may have to be used together to make it tidy. Let's take a look at the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp = pd.read_csv('../data/tidy/temp_flow_pressure.csv')\n",
    "tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the Variables\n",
    "Identifying variables in this dataset is not as straightforward as it is in others. There are variables in a column and as column names.\n",
    "\n",
    "We can use the following as variables:\n",
    "\n",
    "* Group\n",
    "* Pressure\n",
    "* Temperature\n",
    "* Flow\n",
    "* Years\n",
    "\n",
    "The years are column names and the pressure, temperature, and flow are values in the property column. The Group column is the only one in the correct place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt the years\n",
    "Tidying this particular dataset must happen in multiple stages. We won't be able to tidy each variable at the same time. We will begin by melting the year column names into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_melt = tfp.melt(id_vars=['Group', 'Property'], \n",
    "                  value_vars=['2012', '2013', '2014', '2015', '2016'],\n",
    "                  var_name='Year')\n",
    "tfp_melt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to pivot Property\n",
    "We now need to pivot the **Property** column so that the values become column names, and keep Group and Year as columns. The values will come from the **`value`** column.\n",
    "\n",
    "### Problem! `pivot` only works with a single column as the index\n",
    "If we try and pivot by passing a list of values to the **`index`** parameter, we get an error. Pandas actually thinks we are using the `['Group', 'Year']` not as column names but as values to pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_melt.pivot(index=['Group', 'Year'], columns='Property', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Must use `pivot_table`\n",
    "The **`pivot_table`** method does allow us to keep multiple columns in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_tidy = tfp_melt.pivot_table(index=['Group', 'Year'], columns='Property', values='value')\n",
    "tfp_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doesn't `pivot_table` aggregate the values?\n",
    "Yes, **`pivot_table`** always aggregates the values in the intersection of index and columns, and by default takes the mean. In this example, there is only one value per intersection, so the mean will be exactly that value. Let's verify that there is one value per intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_melt.pivot_table(index=['Group', 'Year'], columns='Property', values='value', aggfunc='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_tidy = tfp_tidy.reset_index()\n",
    "tfp_tidy.columns.name = None\n",
    "tfp_tidy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_tidy['Year'] = tfp_tidy['Year'].astype('int')\n",
    "tfp_tidy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to produce tidy data\n",
    "Though, there won't be an exact set of procedures that will result in a tidy dataset, this loose guideline may help you turn messy data into tidy data.\n",
    "\n",
    "1. Identify each variable\n",
    "1. Look for variable names masquerading as column names\n",
    "1. Look for column names masquerading as variable values\n",
    "1. Examine the 5 types of common messy data sets to see which one your dataset most closely resembles\n",
    "1. You will likely need to use **`melt`**, **`pivot`**, and **`pivot_table`**\n",
    "1. You might need to separate different variables into their own DataFrame to make for easier tidying\n",
    "1. Parse string data with the **`str`** accessor with the help of regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Make the **`tidy/country_hour_price.csv`** dataset tidy by putting all the hour columns into a single column.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">If the resulting DataFrame from problem 1 has the strings 'HOUR1' and 'HOUR2' as values in the hour column, then extract just the numerical part of the strings and reassign the result to the hour column.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Read in the titanic dataset (**`tidy/titanic.csv`**) and output the first few rows. Extract the first character of the **`Ticket`** column and save it as a new column **`ticket_first`**. Find the total number of survivors, the total number of passengers, and the percentage of those who survived **by this column**. Next find the total survival rate for the entire dataset. Does this new column help predict who survived?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">If you did problem 2 correctly, you should see that only 7% of the people with tickets that began with 'A' survived. Find the survival rate for all those 'A' tickets by **`Sex`**.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">Find the survival rate by the last letter of the ticket. Is there any predictive power here?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "<span  style=\"color:green; font-size:16px\">Find the length of each passengers name and assign to the **`name_len`** column. What is the minimum and maximum name length?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "<span  style=\"color:green; font-size:16px\">Pass the **`name_len`** column to the **`pd.cut`** function. Also, pass a list of equal-sized cut points to the **`bins`** parameter. Assign the resulting Series to the **`name_len_cat`** column. Find the frequency count of each bin in this column.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8\n",
    "<span  style=\"color:green; font-size:16px\">Is name length a good predictor of survival?<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9\n",
    "<span  style=\"color:green; font-size:16px\">Why do you think people with longer names had a better chance at survival?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10\n",
    "<span  style=\"color:green; font-size:16px\">Using the titanic dataset, do your best to extract the title from a person's name. Examples of title are 'Mr.', 'Dr.', 'Miss', etc... Save this to a column called **`title`**. Find the frequency count of the titles.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11\n",
    "<span  style=\"color:green; font-size:16px\">Does the title have good predictive value of survival?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 12\n",
    "<span  style=\"color:green; font-size:16px\">Create a pivot table of survival by title and sex. Use two aggregation functions, mean and size</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 13\n",
    "<span  style=\"color:green; font-size:16px\">Attempt to extract the first name of each passenger into the column **`first_name`**. Are there are males and females with the same first name?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 14\n",
    "<span  style=\"color:green; font-size:16px\">The past several problems have been an exercise in **feature engineering**. Several new features (columns) have been created from existing columns. Come up with your own feature and test it out on survival.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
