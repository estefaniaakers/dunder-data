{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Dictionary\n",
    "\n",
    "### Objectives\n",
    "\n",
    "* Understand how a data analysis routine can be helpful\n",
    "* Understand what exploratory data analysis (EDA) is\n",
    "* Know the difference between EDA and statistical modeling\n",
    "* Know the difference between univariate and multivariate data\n",
    "* Know graphical and non-graphical EDA techniques to apply to univariate and multivariate data\n",
    "\n",
    "### Resources\n",
    "\n",
    "* Read [chapter 4 of this book](http://www.stat.cmu.edu/~hseltman/309/Book/) by Howard Seltman\n",
    "* Data driven articles from [FiveThirtyEight](https://fivethirtyeight.com/)\n",
    "* [Udacity class on EDA in R](https://classroom.udacity.com/courses/ud651)\n",
    "* [Stanford Visualization Class](http://web.stanford.edu/class/cs448b/cgi-bin/wiki-fa16/index.php?title=Main_Page)\n",
    "* [Good blog post on diamonds EDA](https://solomonmessing.wordpress.com/2014/01/19/visualization-series-the-scatterplot-or-how-to-use-data-so-you-dont-get-ripped-off/)\n",
    "* [Kaggle Winner Interviews](http://blog.kaggle.com/category/winners-interviews/)\n",
    "\n",
    "## What is EDA?\n",
    "Exploratory data analysis is an approach one has when first examining a dataset to gather a fundamental understanding of it without formal statistical hypothesis testing. EDA helps you have an elementary understanding of your dataset through both visualization and descriptive statistics. Usually, no formal conclusions are drawn. \n",
    "\n",
    "### EDA helps you discover a project/hypothesis\n",
    "As you are completing EDA, you might want to investigate a particular path further with more detail which can lead to building an entire project or making a hypothesis that will be rigorously tested. It's not important to know what  you want to discover before beginning EDA.\n",
    "\n",
    "## Developing a Data Analysis Routine\n",
    "Do you have a plan when the data gets in your hands or do you just randomly explore data until you find something interesting? Developing a routine can help you ensure that you follow a common set of procedures during each analysis. This is no different than an airline pilot going through routine safety checks or a professional golfer approaching each golf shot the same way. The notebook **EDA Checklist** contains all of the ideas mentioned in this chapter and can be used as a template for developing your own routine.\n",
    "\n",
    "### Visualization and descriptive statistics are the primary tools of EDA\n",
    "I am naturally drawn to reading articles that have good data visualizations embedded within them. There's nothing like obtaining information from an interesting data visualization. Most EDA make heavy use of visualizations to \n",
    "\n",
    "### No formal hypothesis testing \n",
    "EDA does not usually concern itself with formal statistical hypothesis testing. Statistical analysis is still done by calculating descriptive statistics and correlations. \n",
    "\n",
    "## Final Product of EDA\n",
    "\n",
    "## EDA with Diamonds\n",
    "A popular dataset for beginning exploration is the [diamonds dataset used extensively in examples by the ggplot2][1] R visualization library.\n",
    "\n",
    "[1]: http://ggplot2.tidyverse.org/reference/diamonds.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Dictionary\n",
    "The data dictionary is a file that contains information about every column of your dataset. If there is no data dictionary, you need to create one when beginning EDA. At a minimum, a data dictionary needs to have the column name, description, and data type of each column.\n",
    "\n",
    "Let's look at the data dictionary for the diamonds dataset. Notice that the `Column Name` column is set as the index. This will be important soon when appending new columns to the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 120\n",
    "diamonds_dictionary = pd.read_csv('../data/diamonds_dictionary.csv', index_col='Column Name')\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first look at the data\n",
    "Read in the dataset and inspect the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv('../data/diamonds.csv')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many rows and columns are there?\n",
    "Let's get the dimensions of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the data tidy?\n",
    "Once you first take a look at your data, you need to determine if it is tidy or not.\n",
    "\n",
    "Our diamond dataset is tidy. All column names represent variables and each row is a single observation. From the little I know on diamonds, it appears that the whole table is one observational unit. We could possibly think about putting x, y, z, table and depth in a separate table as they all relate to measurements but having all the columns together makes for easier analysis.\n",
    "\n",
    "## Data Types\n",
    "Once we determine that the data set is tidy, we can find the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Columns to appropriate data types\n",
    "Ensure that the data types match the type that you expect. Be mindful of the common scenario of a column of numeric data being read in as a column of strings.\n",
    "\n",
    "The diamonds dataset seems to have been read with the appropriate data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the data types to the data dictionary\n",
    "Notice that the `price` column is the 6th index value in the data dictionary but the 7th in the `diamonds.dtypes` Series. When we run the new column assignment below, the indexes align first and then the `Data Type` column gets created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Data Type'] = diamonds.dtypes\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get count of unique values for each column\n",
    "The **`nunique`** DataFrame method returns the count of unique values for each column. This can help determine if a numeric variable might be served best as categorical. Again, automatic alignment of the index will ensure that the values are in the correct cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du = diamonds.nunique()\n",
    "du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Num Unique'] = du\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label type of data\n",
    "Provide a generic labeling of each column of data as either continuous, ordinal, or nominal. Use the data dictionary to help determine this label. In this example, all of the string columns are ordinal and there are no nominal columns.\n",
    "\n",
    "We create a Python dictionary mapping the column name to the label and then create a Series from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, o, n = 'continuous', 'ordinal', 'nominal'\n",
    "\n",
    "d = {'carat':    c, \n",
    "     'clarity':  o, \n",
    "     'color':    o, \n",
    "     'cut':      o, \n",
    "     'depth':    c, \n",
    "     'price':    c, \n",
    "     'table':    c, \n",
    "     'x':        c, \n",
    "     'y':        c, \n",
    "     'z':        c}\n",
    "\n",
    "type_label = pd.Series(d)\n",
    "type_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget columns\n",
    "Manually typing out columns is a recipe for typos and outright leaving one out. Use the `columns` attribute to output all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to data  dictionary\n",
    "We can add this new column directly to our data because of automatic index alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Data Type Info'] = type_label\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearranging the column order\n",
    "Once the data is in your hands, you have control to change it. It isn't necessary to keep the original column order. Even though the diamonds dataset only has 10 columns, we can still rearrange it such that it is more meaningful. \n",
    "\n",
    "### Strategies for ordering columns\n",
    "* Place more important columns to the left and less important ones to the right.\n",
    "* Place columns of strings that help identify the row first\n",
    "* Group similar columns together (like start and end time of a bike ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old order\n",
    "diamonds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['cut', 'color', 'clarity','carat', 'price', 'x', 'y','z','depth', 'table']\n",
    "diamonds = diamonds[new_order]\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that the number of columns are the same\n",
    "Make sure you haven't accidentally dropped a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the number of missing values in each column\n",
    "We sum up the number of missing values in each column and append it to the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing = diamonds.isna().sum()\n",
    "num_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the number of missing values to the data dictionaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Missing Values'] = num_missing\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing missing data\n",
    "Understanding missing data is essential to completing an informative EDA. At this step, we can simply be aware of how many there are and do analysis on them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Complete these steps on your dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
