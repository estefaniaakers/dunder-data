{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Objectives\n",
    "\n",
    "\n",
    "1. Interview datasets and tell their story\n",
    "1. Know the difference between exploratory data analysis (EDA) and statistical modeling\n",
    "1. Know the difference between a categorical and a continuous variable\n",
    "1. Know the difference between an ordinal and nominal categorical variable\n",
    "1. Know the difference between univariate and bivariate data\n",
    "1. Know graphical and non-graphical EDA techniques to apply to univariate and bivariate data\n",
    "\n",
    "### Resources\n",
    "\n",
    "1. Read [chapter 4 of this book](http://www.stat.cmu.edu/~hseltman/309/Book/) by Howard Seltman\n",
    "1. Read about the [categorical data type](http://pandas.pydata.org/pandas-docs/stable/categorical.html) in the pandas documentation.\n",
    "\n",
    "More Resources\n",
    "1. [Udacity class on EDA in R](https://classroom.udacity.com/courses/ud651)\n",
    "1. [Stanford Visualization Class](http://web.stanford.edu/class/cs448b/cgi-bin/wiki-fa16/index.php?title=Main_Page)\n",
    "1. [Great blog post on diamonds EDA](https://solomonmessing.wordpress.com/2014/01/19/visualization-series-the-scatterplot-or-how-to-use-data-so-you-dont-get-ripped-off/)\n",
    "1. [Kaggle Winner Interviews](http://blog.kaggle.com/category/winners-interviews/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ds_life.png)\n",
    "\n",
    "[From Microsoft](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview)\n",
    "\n",
    "# Introduction\n",
    "The data science life cycle diagram above is a representation of what an end-to-end data analysis workflow would look like. \n",
    "\n",
    "\n",
    "# Developing a Data Analysis Routine\n",
    "Do you have a plan when the data gets in your hands or do you just randomly explore data until you reach a conclusion? Developing a routine can help you ensure that you follow a common set of procedures during each analysis. This is no different than an airline pilot going through routine safety checks or a professional golfer approaching each golf shot the same way. The notebook **EDA Checklist** lists all of the ideas mentioned in this notebook and can be used as a template for developing your own routine.\n",
    "\n",
    "### Visualization is the primary tool of EDA\n",
    "The primary investigative results that your EDA should produce are visualizations Seaborn and pandas automatically take care of much of this for us.\n",
    "\n",
    "### Descriptive statistics are a close second\n",
    "Along with visualizations come descriptive statistics. A good data visualization should contain most of what can be calculated and outputted into a table. Nevertheless, summary statistics give precise information. \n",
    "\n",
    "### No formal hypothesis testing \n",
    "EDA does not usually concern itself with formal statistical hypothesis testing. Statistical analysis is still done by calculating descriptive statistics and correlations. \n",
    "\n",
    "# EDA with Diamonds\n",
    "One of the most popular datasets for beginning exploration is the [diamonds dataset made famous by the ggplot2](http://ggplot2.tidyverse.org/reference/diamonds.html) R visualization library.\n",
    "\n",
    "# The Data Dictionary\n",
    "The data dictionary is a file that contains information about your dataset. If there is no data dictionary, you need to create it as you complete your EDA. At a minimum, a data dictionary needs to have the column name, description and data type.\n",
    "\n",
    "Let's look at the data dictionary for the diamonds dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_colwidth = 120\n",
    "diamonds_dictionary = pd.read_csv('../data/diamonds_dictionary.csv', index_col='Column Name')\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tidy data and data types\n",
    "\n",
    "## Inspect the first few rows\n",
    "Let's look at the head of the DataFrame and inspect the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv('../data/diamonds.csv')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the data tidy?\n",
    "Once you first take a look at your data, you need to determine if it is tidy or not. For that you need to review the tidy notebook or as summary - answer the following questions.\n",
    "\n",
    "* Is every column a variable?\n",
    "* Is every row an observation?\n",
    "* Is every table a single observational unit?\n",
    "\n",
    "To answer these questions you need to identify your variables first. Lots of data that will end up in your hands will come from a formal relational database. Much of this data is already tidy. Data from excel spreadsheets, government data, summarized data from web scraping, etc.. will usually not be tidy and you will need to work on tidying the data first before doing any analysis.\n",
    "\n",
    "Our diamond dataset is tidy. All column names represent variables and each row is a single observation. From the little we know on diamonds, it appears that the whole table is one observational unit. We could possibly think about putting x, y, z, table and depth in a separate table as they all relate to measurements but having all the columns together makes for easier analysis.\n",
    "\n",
    "# Data Types\n",
    "\n",
    "Once we determine that the data set is tidy, we can find the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the data dictionary\n",
    "The index auto-aligns here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Data Type'] = diamonds.dtypes\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of variables: Categorical or Continuous\n",
    "The two broad classes of variables in a dataset are categorical and continuous. Categorical data is limited to finite, discrete values and can be either strings or numbers. Continuous variables can take on an infinite set of values and are always numeric. \n",
    "\n",
    "### Types of categorical data: ordinal or nominal\n",
    "Categorical data can be further subdivided into two different types - ordinal and nominal. Ordinal data has a natural ordering but the difference between the orders is not measurable. Cancer is usually categorized into 4 stages with 4 being the worst. It is not clear how much worse stage 4 is than stage 3. \n",
    "\n",
    "Nominal data is any other type of categorical data that has no natural ordering like type of coffee or hair color or TV show. Let's add a further classification to our data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, o, n = 'continuous', 'ordinal', 'nominal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'carat':c, 'clarity':o, 'color':o, 'cut':o, 'depth':c, \n",
    "     'price':c, 'table':c, 'x':c, 'y':c, 'z':c}\n",
    "\n",
    "diamonds_dictionary['Data Type Info'] = pd.Series(d)\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearranging the column order\n",
    "You should not accept the default column ordering of your dataset. It might be sufficient but once the data is in your hands, you have control to change it. Even though the diamonds dataset only has 10 columns, we can still rearrange it such that it is more meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old order\n",
    "diamonds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['cut', 'color', 'clarity','carat', 'price', 'x', 'y','z','depth', 'table']\n",
    "diamonds = diamonds[new_order]\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more metadata\n",
    "Let's get the number of observations and the number of missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the number of missing values to the data dictionaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_dictionary['Missing Values'] = diamonds.isna().sum()\n",
    "diamonds_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Perform the same steps with your dataset in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Univariate Analysis\n",
    "\n",
    "### Univariate vs Bivariate (and multivariate) Analyses\n",
    "Univariate analysis is done on one variable at a time. Bivariate or multivariate is analysis done on 2 or more variables.\n",
    "\n",
    "### Graphical vs Non-graphical\n",
    "Each exploratory analysis will either result in either a graph or some numbers representing the data.\n",
    "\n",
    "## Summary Table\n",
    "To help guide you on your exploratory data analysis, a suggested plot/table is given in the 10 table cells below.\n",
    "\n",
    "| Univariate             | Graphical                               | Non-Graphical                     | \n",
    "|-------------|-----------------------------------------|-----------------------------------|\n",
    "| Categorical | Bar char of frequencies (count/percent) | Contingency table (count/percent) |\n",
    "| Continuous  | Histogram/KDE, box/violin, qqplot, fat tails  | central tendency -mean/median/mode, spread - variance, std, skew, kurt, IQR  |\n",
    "\n",
    "| Bivariate/multivariate            | Graphical                               | Non-Graphical                     | \n",
    "|-------------|-----------------------------------------|-----------------------------------|\n",
    "| Categorical vs Categorical | heat map, mosaic plot | Two-way Contingency table (count/percent) |\n",
    "| Continuous vs Continuous  | all pairwise scatterplots, kde, heatmaps |  all pairwise correlation/regression   |\n",
    "| Categorical vs Continuous  | All seaborn \"categorical\" plots | Summary statistics for each level |\n",
    "\n",
    "## Begin with Univariate Analysis\n",
    "After you have tidied the data and began the data dictionary, a reasonable place to start is with univariate analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical or Continuous\n",
    "The **`dtypes`** method outputs the pandas data types but does not directly tell us whether the variable is continuous or categorical.\n",
    "\n",
    "Numeric variables are not necessarily continuous. Columns with limited discrete numeric values are candidates for being categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv('../data/diamonds.csv')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning continuous variables\n",
    "It is also possible to bin continuous variables into categories. We are all naturally fond of this when receiving grades: 90 - 100 is mapped to an **A** with 80 - 89 mapped to **B** and so on.\n",
    "\n",
    "### Get count of unique values for each\n",
    "The **`nunique`** DataFrame method returns the count of unique values for each column. This can help determine if a continuous variable might be served best as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis: Interview each column\n",
    "Univariate analysis is simply an analysis done on one variable. For smaller datasets, I like to manually examine each variable. This way, I can learn the distribution of each variable, discover potential outliers, missing values and simplify matters by concentrating on only variable at a time.\n",
    "\n",
    "Non-graphical univariate analysis for categorical data is pretty bland as there is not much to do except report the count or relative frequency. \n",
    "\n",
    "### Quickly done with `describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis on the categorical variables\n",
    "The frequency of occurrence of each value by raw count and percentage is usually the first (and many times only exploratory step taken) when doing univariate categorical analysis. The **`value_counts`** Series method will be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalize=True to get percentage\n",
    "diamonds['cut'].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers for categorical variables\n",
    "Categorical columns that have values with very few counts may be considered an outlier. \n",
    "\n",
    "### Change low values to \"other\"\n",
    "We can set a threshold of a minimum number of counts and change these values to \"other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing `object` to `category`\n",
    "Let's change actual categorical values to the Pandas `category` data type. Changing the column to type **`category`** does several things. \n",
    "* It saves memory by encoding each category as a numerical value. \n",
    "* Sorting is possible by the category order (if given). \n",
    "* The **`.cat`** accessor makes many more methods available.\n",
    "\n",
    "### Use `pd.Categorical`\n",
    "\n",
    "Ordinal variables can be given their ordering through the **`categories`** parameter with **`ordered`** set equal to **`True`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
    "diamonds['cut'] = pd.Categorical(diamonds['cut'], ordered=True, categories=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the data type is now a categiry and the categories are ordered\n",
    "diamonds['cut'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert color and clarity to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
    "diamonds['color'] = pd.Categorical(diamonds['color'], ordered=True, categories=order)\n",
    "\n",
    "order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "diamonds['clarity'] = pd.Categorical(diamonds['clarity'], ordered=True, categories=order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For nominal categories\n",
    "There is no need to specify `ordered` or `categories` for nominal variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by frequency and then by category\n",
    "The **`value_counts`** method works as before by showing the frequencies in descending order. Chaining the **`sort_index`** method displays the power of pandas categorical variables by sorting by the given categorical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['color'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages\n",
    "diamonds['color'].value_counts(normalize=True).round(3).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['color'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn sorts axis automatically\n",
    "Conveniently, seaborn sorts the categorical variable axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='color', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='cut', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='clarity', data=diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie charts are evil\n",
    "Lots of data visualization experts say to [avoid pie charts](https://www.quora.com/How-and-why-are-pie-charts-considered-evil-by-data-visualization-experts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.color.value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "Do univariate analysis on the categorical columns. Convert them to the `category` type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. More Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Columns of Strings\n",
    "Categorical columns don't lend themselves to much exploratory data analysis. Features (new variables) may be created from strings. For instance, the first or last letter can be pulled out into its own column for further analysis. The second word of a sentence, the count of the number of vowels and so forth.\n",
    "\n",
    "Just because a column is a string does not mean a single bar plot of frequencies ends the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis on carat\n",
    "Carat is numerical and therefore a much larger array of statistics may be generated to describe the variable. A boxplot is great to see some measure of spread and have some cut-off for outliers, defaulting to 1.5 times the IQR. There appear to be quite a few outliers, seen by the dots beyond the whisker of the plot below.\n",
    "\n",
    "The density of the distribution is not visible with a box plot. For all I know, 99.9% of the data could be less than 2. Use a KDE or histogram for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='carat', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(diamonds['carat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More precision about distribution\n",
    "96% percent of the diamonds are 2 carats are less and 99.7% are 2.5 carats or less. 99% of the diamonds are between .23 and 2.31 carats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['carat'].quantile([.005, .995])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Complete some univariate analysis on some continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Outliers (in one dimension)\n",
    "There is no formal statistical definition of an outlier but generally speaking, we think of outliers as being an abnormal observation distant from other points. There has been lots of research [dedicated to outlier detection](https://en.wikipedia.org/wiki/Outlier#Detection) but for our purposes we will concentrate on allowing our natural human ability to notice slight imperfections from a standard.\n",
    "\n",
    "Box plots are great tools for visually detecting outliers. Seaborn (and most other plotting tools) defaults to labeling outliers as any observation more than 1.5 times the IQR beyond either the first or third quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = diamonds.dtypes != 'category'\n",
    "diamonds.columns[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_num = diamonds.select_dtypes(exclude='category')\n",
    "dia_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_num_melt = dia_num.melt()\n",
    "dia_num_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='value', data=dia_num_melt, kind='box', col='variable', col_wrap=3, sharex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers\n",
    "During EDA, we are not necessarily interested in taking an action on the outlier. Instead we can label it, investigate it further and then make a decision on it.\n",
    "\n",
    "### Labeling the outliers\n",
    "A column will now be created to label the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ((diamonds['x'] < 3) | (diamonds['y'] > 30) | (diamonds['y'] > 20) | \n",
    "            (diamonds['carat'] > 4) | (diamonds['depth'] < 45) | (diamonds['depth'] > 75) |\n",
    "            (diamonds['table'] < 40) | (diamonds['table'] > 90)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['outliers'] = outliers\n",
    "filt = diamonds['outliers'] == 1\n",
    "diamonds[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on outliers\n",
    "* There are 7 rows with x,y,z all equal to 0. These variables must be positive, so they can't possibly be correct. \n",
    "* The two y values over 30mm can't possibly be right as one of them would be wider than the largest diamond ever found and the price is much too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculated Depth\n",
    "The data dictionary tells us that the **`depth`** is equal to **`z / mean(x,y)`**. Let's calculate the depth using this formula and compare to the depth from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['calculated_depth'] = diamonds['z'] / ((diamonds['x'] + diamonds['y']) / 2) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['depth_diff'] = (diamonds['depth'] - diamonds['calculated_depth']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.sort_values('depth_diff', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(diamonds['depth_diff'] < 5).mean(), (diamonds['depth_diff'] > 5).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### depth vs calculated depth\n",
    "If this was a pristine dataset, then the calculated depth would equal the depth for each observation. About .1% (or 40) of the observations have an absolute depth difference less than 1. What does this mean for the other .2% of the data? There must be a measurement/input error in x, y or z. The table above sorts by largest absolute depth difference. A **`z`** of 0 is responsible for much of the large depth differences.\n",
    "\n",
    "More investigation into these wrong calculated depth observations might need to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated rows\n",
    "Looking back up at the outliers table, it appears that several pairs of observations are identical or very similar (see 49556 and 49557). All the duplicated rows are saved to the **`dupes`** DataFrame. Perhaps the duplicates should be dropped. More information is needed. There are 289 duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = diamonds[diamonds.duplicated(keep=False)]\n",
    "dupes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Try and discover outliers and find duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bivariate and Multivariate EDA\n",
    "All the above EDA focused on a single column at one time (univariate). Of course it is possible to extend a data analyses to multiple columns but the amount of combinations of plots and tables grows as if there are n columns then three are **n choose 2** bivariate combinations. With the 11 original variables, this would make 55 bivariate combinations and 165 involving three variables at a time.\n",
    "\n",
    "Look way back at [the table summarizing](#Summarizing) the types of graphical and non-graphical tools for the different combinations of variables.\n",
    "\n",
    "* categorical vs categorical\n",
    "* categorical vs continuous\n",
    "* continuous vs continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical vs Categorical\n",
    "Let's create two-way contingency tables and heat maps to help show the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_clar_ct = diamonds.pivot_table(index='clarity', columns='color', aggfunc='size')\n",
    "col_clar_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier to see areas where data is denser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk of the data is in the middle\n",
    "sns.heatmap(col_clar_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_color_ct = diamonds.pivot_table(index='cut', columns='color', aggfunc='size')\n",
    "cut_color_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cut_color_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_color_pct = pd.crosstab(diamonds['cut'], diamonds['color'], normalize='all')\n",
    "cut_color_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cut_color_pct, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Do some analysis on categorical vs categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Categorical vs Continuous\n",
    "All the plots in the categorical section in the [seaborn tutorial](http://seaborn.pydata.org/tutorial/categorical.html) will be of major help here. \n",
    "\n",
    "### A loose problem statement\n",
    "The rest of the notebook will work on discovering how price per carat changes with respect to the variables. This variable does not exist yet so we will need to create it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['price_per_carat'] = diamonds['price'] / diamonds['carat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing all categories vs all continuous variables\n",
    "The Figure below, plots the mean at every level of category for all the continuous variables. All three categorical variables are ordered and displayed in the given order.\n",
    "\n",
    "Very interestingly, all the continuous variables decline as the categorical variables increase. carat, x, y, z, and table seem to be closely related to the size of the diamond and so it appears that it is harder and harder to find high-quality large diamonds.\n",
    "\n",
    "The only continuous variable that increased is price per carat. I would have expected it to increase more for the higher quality diamonds, but unexpectedly it only increases a small amount and the highest quality diamonds do not always average the highest prices. Why is this so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(diamonds,\n",
    "                 x_vars=[\"color\", \"cut\", \"clarity\"],\n",
    "                 y_vars=[\"carat\", \"price\", \"price_per_carat\", \"table\", \"x\", \"y\", \"z\"], height=3, aspect=1.5)\n",
    "g.map(sns.pointplot, ci=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price per carat vs clarity and color\n",
    "It does not seem like there is much of a relationship between price per carat and clarity and color unless you are looking at the first and last plots below.\n",
    "\n",
    "The middle 6 plots all look virtually identical. The **I1** clarity graph is significantly less that the rest. Colors **E** and **D** in the **IF** clarity graph are also clearly above the result.\n",
    "\n",
    "### Multiplicative effect\n",
    "Since the clarity and color do not seem to have an effect until you have either awful or amazing diamonds, the effects of having both very good or both very poor might be like multiplying their values together for an even much larger gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='color', y='price_per_carat', data=diamonds, kind='bar', col='clarity', col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut might not have an effect\n",
    "Plotting cut and color vs price per carat shows nearly identical graphs for all the cut types. Even **ideal** cut diamonds are no better than the others. The worst **color** **fair** cut diamonds tend to be a bit worse than average. But overall, cut does not look like it has much of an effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='color', y='price_per_carat', data=diamonds, kind='bar', col='cut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map to identify high and low prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_clarity_price_mean = diamonds.pivot_table(index='color', columns='clarity', values='price_per_carat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(color_clarity_price_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Make some plots on categorical vs continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Continuous vs Continuous\n",
    "A pairwise scatter plot is a fantastic first assessment of the relationships between continuous variables. Examining every combination of continuous variables might make for a terribly large plot so using a heat/cluster map like the one below to first find the highest correlated variables can help narrow down the choices.\n",
    "\n",
    "Coloring the points by a third variable aids quite in the understanding. It is clear that carat is highly correlated with price and price per carat. The variables x, y, and z were not used in this plot because they are highly correlated with one another and highly correlated with carat. The variable carat essentially takes the place for the other variables.\n",
    "\n",
    "Since the diamond dataset is fairly large, plotting 50,000 points will take some time. Many points will overlap. To help alleviate this computational load, use the **`sample`** method to select a random sample of the data. The marker size of each point has also been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(diamonds.sample(frac=.3), \n",
    "             diag_kind='kde',\n",
    "             vars=['carat', 'price', 'price_per_carat', 'depth'],\n",
    "             hue='color', \n",
    "             plot_kws={\"s\": 3}, \n",
    "             height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the **hue** by a different categorical variable\n",
    "The above shows a clear relationship between carat and price. It also shows that the **color** of each stone is important. If we examine a vertical strip of data for carat vs price we notice that color **D** is always the highest.\n",
    "\n",
    "But very interestingly, the frequency of color D stones decrease as carats increase. In fact, it appears there are almost no color D stones larger than 2 carats. Perhaps larger diamonds are of poorer quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(diamonds.sample(frac=.3), \n",
    "             diag_kind='kde',\n",
    "             vars=['carat', 'price', 'price_per_carat', 'depth'],\n",
    "             hue='clarity', \n",
    "             plot_kws={\"s\": 3}, \n",
    "             height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "The variables, price, price per carat, carat, x, y and z are all very tightly clustered together and all highly correlated with one another. The hierarchical cluster map makes this easy to spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(diamonds.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "Do some continuous vs continuous analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Binning a Continuous variable\n",
    "\n",
    "## Uneven distribution of high quality diamonds\n",
    "The scatter plots above indicate that higher quality diamonds tend to me smaller in size. Take a look at the box plots below. It is clear that the highest quality diamonds, D color and IF clarity are much lower average carat size. The largest diamonds are the worst quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='color', y='carat', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='clarity', y='carat', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='cut', y='carat', data=diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Making a categorical variable out of a continuous variable\n",
    "Occasionally, you will want to code different ranges of a continuous variable as a categorical variable as was talked about with numerical grades converting to letter grades.\n",
    "\n",
    "Our point plots from way above indicated that price decreased as the quality of diamonds increased. How was that possible? Our above box plots indicate that the highest quality diamonds tend to be much smaller on average but larger diamonds are also more expensive. This explains the paradox.\n",
    "\n",
    "To help visualize diamonds of about the same size we can turn our continuous variable **`carat`** into a categorical one with the **`pd.qcut`** function. This will cut the data into equally sized bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates 10 equal sized bins\n",
    "diamonds['carat_category'] = pd.qcut(diamonds['carat'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['carat_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "sns.pointplot(x='clarity', y='price', data=diamonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small diamonds\n",
    "diamonds_small = diamonds[diamonds['carat_category'].cat.codes == 0]\n",
    "sns.pointplot(x='clarity', y='price', data=diamonds_small, ci=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The diamond story in one plot\n",
    "This one plot tells the diamond story. As carat increases, price goes up but it also increases as color and clarity improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='clarity', y='price', data=diamonds, hue='carat_category', col='color', col_wrap=4, kind='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Your Turn\n",
    "Make a categorical variable out a continuous variable and use it to make a plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
