{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Intro to Time Series\n",
    "\n",
    "### Objectives\n",
    "* Make a web request and retrieve JSON data from the IEX trading API\n",
    "* Create a DatetimeIndex and use it for easier subset selection\n",
    "* Learn how to create offset alias strings and pass them to the `asfreq` method to do upsampling/downsampling\n",
    "\n",
    "## Introduction\n",
    "Broadly speaking, time series data are simply points of data gathered over time. The time order is meaningful and typically there is only one observation per unit of time. The time will uniquely identify each record. Often, the time is evenly spaced between each data point. \n",
    "\n",
    "Examples of time series data include stock market closing prices, levels of CO2 in the atmosphere, unemployement rates, etc... Pandas has good functionality with regards to manipulating dates, aggregating over different time periods, sampling different periods of time, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Data\n",
    "There are many tools available to get data stock market data. We will use the [IEX developer platform][1] which has an excellent and easy-to-use API to retrieve market data for free (up to 100 requests per second).\n",
    "\n",
    "### Using the IEX API\n",
    "The IEX API is fairly straightforward to use and there are several examples that you can view to understand how it works. The base URL of the API is `https://api.iextrading.com/1.0` which can be [seen here in the docs][2]. If you scroll down from the last link, you will see how the API is used. Each **endpoint** is documented. Let's use the [chart endpoint][3].\n",
    "\n",
    "We simply append **`/stock/{symbol}/chart/{range}`** to the base URL and put the stock symbol and range of data we want (without the curly braces) to retrieve historical stock price data. Go to the docs to view the available ranges.\n",
    "\n",
    "Let's create our URL:\n",
    "\n",
    "[1]: https://iextrading.com/developer/\n",
    "[2]: https://iextrading.com/developer/docs/#endpoints\n",
    "[3]: https://iextrading.com/developer/docs/#chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.iextrading.com/1.0/stock/AMZN/chart/5y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON objects\n",
    "Most APIs will respond with **JSON** data, a standardized format of data that is very similar to a Python dictionary with key-value pairs. This particular JSON data is returned as a list of dictionaries. We can usually read in an API response with the **`read_json`** pandas function by passing it the URL directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = pd.read_json(url)\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify data types\n",
    "The **`read_json`** function helps choose the correct data types for us. It's a good idea to verify that Pandas chose the correct data types with the **`dtypes`** attribute. A common occurrence is for a column that looks like it contains numeric data to be actually kept as a string.\n",
    "\n",
    "Looking below, the data types seem to all be correct, save for **`label`**, which appears to be just a duplicate of the date column. We are good to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop some columns\n",
    "Let's drop the **`label`**, **`unadjustedVolumne`**, and **`vwap`** columns to get a smaller DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = amzn.drop(columns=['label', 'unadjustedVolume', 'vwap'])\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the `dt` accessor\n",
    "The Series `dt` accessor gives us extra attributes and methods only available to datetime columns. Let's take a look at some of those again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = amzn['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.day_name().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.is_month_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the Datetime column in the index\n",
    "If you do have time series data where the values of one datetime column uniquely identify each row, then you can make for some easier data manipulation by setting this column in the index. Let's do this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = amzn.set_index('date')\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTimeIndex\n",
    "Setting a datetime column as the index technically creates a DateTimeIndex. You can directly call specific datetime methods on it like you can with the `dt` accessor. Let's extract it and see a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = amzn.index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.year[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.month[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.weekday_name[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy subset selection with a DateTimeIndex\n",
    "One big advantage of a DateTimeIndex is the ability to select subsets of data without using boolean indexing. We can use strings to represent specific datetimes and pass those strings to the `loc` indexer. Let's see an example of selecting some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select January 5th, 2017\n",
    "amzn.loc['2017-1-5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial string matching to select entire months or years\n",
    "You can select entire years or months (or other spans of time) by using a string with just less precision than the DateTimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all of January 2017\n",
    "amzn.loc['2017-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all of the year 2017\n",
    "amzn.loc['2017'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing with partial string matching\n",
    "Use slice notation to select a specific date range. Note that the stop value is inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.loc['2017-1-5':'2017-1-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all of January and February of 2017\n",
    "amzn.loc['2017-1':'2017-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Specific Times\n",
    "Let's say you are interested in selecting the closing prices for the last day of every year in the dataset. Pandas provides the `asfreq` method to do so. You must pass it an **offset alias** as a string. An offset alias determines the frequency of the time series data you would like to sample. You must reference the offset aliases in the Pandas documentation. It has been provided for you as an iframe (an html document embedded inside of another html document) in this notebook below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset aliases\n",
    "For instance, in our case we might want to use the offset alias 'A' (or equivalently 'Y') as the table above tells us it is the year end frequency. We pass this as a string to the `asfreq` method to return the very last day of the each year.\n",
    "\n",
    "Note, that `asfreq` only works for DataFrames with a DateTimeIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't quite what we want because the stock market is open only during the week and thus some years end on a weekend. Pandas will return rows filled with missing values for dates that we have no data for.\n",
    "\n",
    "Let's use the offset alias 'BA' instead to signify business year end frequency. Now, we select the last trading day of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('BY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchored offset aliases\n",
    "Let's say we would like to select every Friday. We'll need to use a slightly different string called an **anchored offset alias**. The table for these are right below the offset aliases from above, so just scroll down a bit to see them. The documentation alerts us that by default, weeks are anchored to Sunday. We change it to Friday with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('W-FRI').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling - Increasing the number of rows\n",
    "The above selections choose a specific subset of rows. This is called **downsampling** in time series when we select a subset of the original data. \n",
    "\n",
    "Instead, we may choose to **upsample** and increase the number of rows. This will lead to rows of all missing values. Both upsampling and downsampling ensure that the rows are evenly spaced units of time. \n",
    "\n",
    "Let's return a DataFrame with a single row for each day of the year. Currently, only the trading days are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('D').head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use integers in the offset alias\n",
    "You can upsample/downsample by appending an integer to the front of the offset alias. These represent the number of offset aliases. For example, '3M' stands for 3 months and '15s' for 15 seconds.\n",
    "\n",
    "To select every 6th Wednesday, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('6W-WED').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also upsample by smaller units than what is present in the index. For instance, '4H' will make a new row for every 4 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('4H').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can fill in the missing values with the previous or next known values using the `method` parameter which can be set to either 'ffill' or 'bfill'. Here we fill the missing values using the previously known value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.asfreq('4H', method='ffill').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No duplicates are allowed and dates must be ordered\n",
    "Upsampling/downsampling only works properly when there are no duplicate dates and when the data is ordered. Let's take the employee dataset which has a datetime column, but is definitely not time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = pd.read_csv('../data/employee.csv', parse_dates=['hire_date'])\n",
    "emp = emp.set_index('hire_date')\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try and sample it by Year (which is meaningless in this dataset) we get an empty DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.asfreq('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = emp.sort_index()\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we try and make it more like a time series by sorting the index, the operation will only be successful if there are no duplicate dates. The error tells us that at least one hire date is not unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.asfreq('W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection with partial string still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.loc['2012-1':'2012-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in the weather time series dataset and place the date column in the index.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">What was the temperature on June 11, 2011?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">How many days did it rain during the last three months of 2011?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Which year had more snow days, 2007 or 2012?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">Select every other thursday</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "<span  style=\"color:green; font-size:16px\">Select the first day of each month.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has special objects called **offsets** that can be used in place of offset alias strings. Below we create our own custom offset object.\n",
    "\n",
    "The stock market is actually closed on some Fridays due to holidays so it wouldn't make sense to select every single Friday, but instead only the Fridays that were actual trading days. We have to dig a bit deeper into Pandas and create a custom business day that is aware of the US Federal Holiday Calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "custom_bday = CustomBusinessDay(calendar=USFederalHolidayCalendar(), weekmask='Fri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(custom_bday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original selection was the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = amzn.asfreq('W-Fri')\n",
    "orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our custom business day, we removed 6 Fridays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = amzn.asfreq(custom_bday)\n",
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating date ranges\n",
    "It is possible to create your own equally spaced interval of time with the `date_range` function. It returns a DateTimeIndex which you can use to set as the index in your own DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 values begining with January 1, 2012 every 20 seconds.\n",
    "idx = pd.date_range(start='1/1/2012', periods=10, freq='20S')\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 8 equally spaced periods between two dates\n",
    "idx = pd.date_range(start='1/1/2012', end='10/1/2012', periods=8)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the frequency between two dates - here 10 days and 15 seconds\n",
    "idx = pd.date_range(start='1/1/2012', end='10/1/2012', freq='10D 15s')\n",
    "idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
